# ğŸ“Œ Spur AI Support Agent

A **full-stack AI-powered customer support chat application** built as part of the **Spur Software Engineer Hiring Assignment**.
The app allows users to chat with an AI support agent, maintains conversation sessions, and stores chat history securely.

---

## ğŸš€ Features

* ğŸ’¬ Real-time AI chat interface
* ğŸ§  AI-powered responses using **Groq (LLaMA 3.1)**
* ğŸ—‚ Session-based conversation history
* ğŸ—„ Persistent storage using **Prisma + SQLite**
* âš¡ Fast and modern frontend using **React + Vite**
* ğŸ”’ Secure handling of API keys using `.env`
* ğŸ§¼ Clean, modular backend architecture

---

## ğŸ›  Tech Stack

### Frontend

* React (TypeScript)
* Vite
* Axios
* CSS (inline styling)

### Backend

* Node.js
* Express.js
* TypeScript
* Prisma ORM
* SQLite database

### AI / LLM

* **Groq API**
* Model: `llama-3.1-8b-instant`

---

## ğŸ“ Project Structure

```
spur-ai-support-agent/
â”œâ”€â”€ spur-frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â”œâ”€â”€ spur-backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ prisma/
â”‚   â”œâ”€â”€ .env
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/YOUR_USERNAME/spur-ai-support-agent.git
cd spur-ai-support-agent
```

---

### 2ï¸âƒ£ Backend Setup

```bash
cd spur-backend
npm install
```

Create a `.env` file in `spur-backend`:

```env
GROQ_API_KEY=your_groq_api_key_here
DATABASE_URL=file:./prisma/dev.db
```

Run database migration:

```bash
npx prisma migrate dev --name init
```

Start backend server:

```bash
npx ts-node-dev src/index.ts
```

Backend runs on:

```
http://localhost:5000
```

---

### 3ï¸âƒ£ Frontend Setup

Open a new terminal:

```bash
cd spur-frontend
npm install
npm run dev
```

Frontend runs on:

```
http://localhost:5173
```

---

## ğŸ§  How It Works

1. User sends a message from the frontend chat UI
2. Backend:

   * Creates or resumes a conversation session
   * Stores user messages in the database
   * Sends chat history + new message to the LLM
3. AI generates a response
4. Response is stored and returned to the frontend
5. UI updates with auto-scroll and message distinction

---

## ğŸ” Security & Best Practices

* `.env` file is ignored via `.gitignore`
* API keys are never committed
* Database file is ignored from version control
* Modular, maintainable code structure

---

## ğŸ§ª Error Handling

* Graceful handling of empty messages
* LLM API errors are caught and logged
* User receives a friendly fallback message on failure

---

## ğŸ“¸ Screenshots

### ğŸ§  AI Support Chat in Action

<img width="658" height="818" alt="{2EF10AF8-EB4F-4523-BFF4-E2135645AD4E}" src="https://github.com/user-attachments/assets/c01a492f-6c2e-40a6-95b6-ae7f223bc4b1" />

*Example conversation showing the AI assisting a user with placing an order.*

---

## ğŸ“Œ Notes

* LLM provider is abstracted and can be switched easily
* Designed to be scalable and production-ready
* Demonstrates real-world debugging and API integration skills

---

## ğŸ‘©â€ğŸ’» Author

**Kanak**
B.Tech CSE Student
Aspiring Software Engineer

---

## âœ… Status

âœ” Fully functional
âœ” Assignment completed
âœ” Ready for evaluation

---


